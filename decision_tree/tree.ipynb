{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Height  Weight  Index\n",
       "0    Male     174      96      4\n",
       "1    Male     189      87      2\n",
       "2  Female     185     110      4\n",
       "3  Female     195     104      3\n",
       "4    Male     149      61      3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['obese'] = (data.Index >= 4).astype('int')\n",
    "data.drop('Index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Misclassified when cutting at 100kg: 18 \n",
      " Misclassified when cutting at 80kg: 63\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\n",
    "  \" Misclassified when cutting at 100kg:\",\n",
    "  data.loc[(data['Weight']>=100) & (data['obese']==0),:].shape[0], \"\\n\",\n",
    "  \"Misclassified when cutting at 80kg:\",\n",
    "  data.loc[(data['Weight']>=80) & (data['obese']==0),:].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4998"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini_impurity(y):\n",
    "  '''\n",
    "  Given a Pandas Series, it calculates the Gini Impurity. \n",
    "  y: variable with which calculate Gini Impurity.\n",
    "  '''\n",
    "  if isinstance(y, pd.Series):\n",
    "    p = y.value_counts()/y.shape[0]\n",
    "    gini = 1-np.sum(p**2)\n",
    "    return(gini)\n",
    "\n",
    "  else:\n",
    "    raise('Object must be a Pandas Series.')\n",
    "\n",
    "gini_impurity(data.Gender) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997114388674198"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(y):\n",
    "  '''\n",
    "  Given a Pandas Series, it calculates the entropy. \n",
    "  y: variable with which calculate entropy.\n",
    "  '''\n",
    "  if isinstance(y, pd.Series):\n",
    "    a = y.value_counts()/y.shape[0]\n",
    "    entropy = np.sum(-a*np.log2(a+1e-9))\n",
    "    return(entropy)\n",
    "\n",
    "  else:\n",
    "    raise('Object must be a Pandas Series.')\n",
    "\n",
    "entropy(data.Gender)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y):\n",
    "  '''\n",
    "  Function to help calculate the variance avoiding nan.\n",
    "  y: variable to calculate variance to. It should be a Pandas Series.\n",
    "  '''\n",
    "  if(len(y) == 1):\n",
    "    return 0\n",
    "  else:\n",
    "    return y.var()\n",
    "\n",
    "def information_gain(y, mask, func=entropy):\n",
    "  '''\n",
    "  It returns the Information Gain of a variable given a loss function.\n",
    "  y: target variable.\n",
    "  mask: split choice.\n",
    "  func: function to be used to calculate Information Gain in case os classification.\n",
    "  '''\n",
    "  \n",
    "  a = sum(mask)\n",
    "  b = mask.shape[0] - a\n",
    "  \n",
    "  if(a == 0 or b ==0): \n",
    "    ig = 0\n",
    "  \n",
    "  else:\n",
    "    if y.dtypes != 'O':\n",
    "      ig = variance(y) - (a/(a+b)* variance(y[mask])) - (b/(a+b)*variance(y[-mask]))\n",
    "    else:\n",
    "      ig = func(y)-a/(a+b)*func(y[mask])-b/(a+b)*func(y[-mask])\n",
    "  \n",
    "  return ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0002808244603315635"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain(data['obese'], data['Gender'] == 'Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best split for Weight is when the variable is less than  103 \n",
      "Information Gain for that split is: 0.10625190497954967\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def categorical_options(a):\n",
    "  '''\n",
    "  Creates all possible combinations from a Pandas Series.\n",
    "  a: Pandas Series from where to get all possible combinations. \n",
    "  '''\n",
    "  a = a.unique()\n",
    "\n",
    "  opciones = []\n",
    "  for L in range(0, len(a)+1):\n",
    "      for subset in itertools.combinations(a, L):\n",
    "          subset = list(subset)\n",
    "          opciones.append(subset)\n",
    "\n",
    "  return opciones[1:-1]\n",
    "\n",
    "def max_information_gain_split(x, y, func=entropy):\n",
    "  '''\n",
    "  Given a predictor & target variable, returns the best split, the error and the type of variable based on a selected cost function.\n",
    "  x: predictor variable as Pandas Series.\n",
    "  y: target variable as Pandas Series.\n",
    "  func: function to be used to calculate the best split.\n",
    "  '''\n",
    "\n",
    "  split_value = []\n",
    "  ig = [] \n",
    "\n",
    "  numeric_variable = True if x.dtypes != 'O' else False\n",
    "\n",
    "  # Create options according to variable type\n",
    "  if numeric_variable:\n",
    "    options = x.sort_values().unique()[1:]\n",
    "  else: \n",
    "    options = categorical_options(x)\n",
    "\n",
    "  # Calculate ig for all values\n",
    "  for val in options:\n",
    "    mask =   x < val if numeric_variable else x.isin(val)\n",
    "    val_ig = information_gain(y, mask, func)\n",
    "    # Append results\n",
    "    ig.append(val_ig)\n",
    "    split_value.append(val)\n",
    "\n",
    "  # Check if there are more than 1 results if not, return False\n",
    "  if len(ig) == 0:\n",
    "    return(None,None,None, False)\n",
    "\n",
    "  else:\n",
    "  # Get results with highest IG\n",
    "    best_ig = max(ig)\n",
    "    best_ig_index = ig.index(best_ig)\n",
    "    best_split = split_value[best_ig_index]\n",
    "    return(best_ig,best_split,numeric_variable, True)\n",
    "\n",
    "\n",
    "weight_ig, weight_slpit, _, _ = max_information_gain_split(data['Weight'], data['obese'],)  \n",
    "\n",
    "\n",
    "print(\n",
    "  \"The best split for Weight is when the variable is less than \",\n",
    "  weight_slpit,\"\\nInformation Gain for that split is:\", weight_ig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>0.106252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Male]</td>\n",
       "      <td>174</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender    Height    Weight\n",
       "0 -0.000281  0.019684  0.106252\n",
       "1    [Male]       174       103\n",
       "2     False      True      True\n",
       "3      True      True      True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('obese', axis= 1).apply(max_information_gain_split, y = data['obese'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(y, data):\n",
    "  '''\n",
    "  Given a data, select the best split and return the variable, the value, the variable type and the information gain.\n",
    "  y: name of the target variable\n",
    "  data: dataframe where to find the best split.\n",
    "  '''\n",
    "  masks = data.drop(y, axis= 1).apply(max_information_gain_split, y = data[y])\n",
    "  if sum(masks.loc[3,:]) == 0:\n",
    "    return(None, None, None, None)\n",
    "\n",
    "  else:\n",
    "    # Get only masks that can be splitted\n",
    "    masks = masks.loc[:,masks.loc[3,:]]\n",
    "\n",
    "    # Get the results for split with highest IG\n",
    "    split_variable = masks.iloc[0].astype(np.float32).idxmax()\n",
    "    #split_valid = masks[split_variable][]\n",
    "    split_value = masks[split_variable][1] \n",
    "    split_ig = masks[split_variable][0]\n",
    "    split_numeric = masks[split_variable][2]\n",
    "\n",
    "    return(split_variable, split_value, split_ig, split_numeric)\n",
    "\n",
    "\n",
    "def make_split(variable, value, data, is_numeric):\n",
    "  '''\n",
    "  Given a data and a split conditions, do the split.\n",
    "  variable: variable with which make the split.\n",
    "  value: value of the variable to make the split.\n",
    "  data: data to be splitted.\n",
    "  is_numeric: boolean considering if the variable to be splitted is numeric or not.\n",
    "  '''\n",
    "  if is_numeric:\n",
    "    data_1 = data[data[variable] < value]\n",
    "    data_2 = data[(data[variable] < value) == False]\n",
    "\n",
    "  else:\n",
    "    data_1 = data[data[variable].isin(value)]\n",
    "    data_2 = data[(data[variable].isin(value)) == False]\n",
    "\n",
    "  return(data_1,data_2)\n",
    "\n",
    "def make_prediction(data, target_factor):\n",
    "  '''\n",
    "  Given the target variable, make a prediction.\n",
    "  data: pandas series for target variable\n",
    "  target_factor: boolean considering if the variable is a factor or not\n",
    "  '''\n",
    "\n",
    "  # Make predictions\n",
    "  if target_factor:\n",
    "    pred = data.value_counts().idxmax()\n",
    "  else:\n",
    "    pred = data.mean()\n",
    "\n",
    "  return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Weight <=  103': [{'Height <=  175': [{'Weight <=  74': [{'Height <=  148': [1,\n",
       "        0]},\n",
       "      {'Height <=  162': [1, {'Weight <=  82': [0, 1]}]}]},\n",
       "    0]},\n",
       "  {'Height <=  189': [{'Weight <=  116': [{'Height <=  168': [1,\n",
       "        {'Height <=  169': [0, 1]}]},\n",
       "      1]},\n",
       "    {'Weight <=  115': [0, 1]}]}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_tree(data,y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):\n",
    "  '''\n",
    "  Trains a Decission Tree\n",
    "  data: Data to be used to train the Decission Tree\n",
    "  y: target variable column name\n",
    "  target_factor: boolean to consider if target variable is factor or numeric.\n",
    "  max_depth: maximum depth to stop splitting.\n",
    "  min_samples_split: minimum number of observations to make a split.\n",
    "  min_information_gain: minimum ig gain to consider a split to be valid.\n",
    "  max_categories: maximum number of different values accepted for categorical values. High number of values will slow down learning process. R\n",
    "  '''\n",
    "\n",
    "  # Check that max_categories is fulfilled\n",
    "  if counter==0:\n",
    "    types = data.dtypes\n",
    "    check_columns = types[types == \"object\"].index\n",
    "    for column in check_columns:\n",
    "      var_length = len(data[column].value_counts()) \n",
    "      if var_length > max_categories:\n",
    "        raise ValueError('The variable ' + column + ' has '+ str(var_length) + ' unique values, which is more than the accepted ones: ' +  str(max_categories))\n",
    "\n",
    "  # Check for depth conditions\n",
    "  if max_depth == None:\n",
    "    depth_cond = True\n",
    "\n",
    "  else:\n",
    "    if counter < max_depth:\n",
    "      depth_cond = True\n",
    "\n",
    "    else:\n",
    "      depth_cond = False\n",
    "\n",
    "  # Check for sample conditions\n",
    "  if min_samples_split == None:\n",
    "    sample_cond = True\n",
    "\n",
    "  else:\n",
    "    if data.shape[0] > min_samples_split:\n",
    "      sample_cond = True\n",
    "\n",
    "    else:\n",
    "      sample_cond = False\n",
    "\n",
    "  # Check for ig condition\n",
    "  if depth_cond & sample_cond:\n",
    "\n",
    "    var,val,ig,var_type = get_best_split(y, data)\n",
    "\n",
    "    # If ig condition is fulfilled, make split \n",
    "    if ig is not None and ig >= min_information_gain:\n",
    "\n",
    "      counter += 1\n",
    "\n",
    "      left,right = make_split(var, val, data,var_type)\n",
    "\n",
    "      # Instantiate sub-tree\n",
    "      split_type = \"<=\" if var_type else \"in\"\n",
    "      question =   \"{} {}  {}\".format(var,split_type,val)\n",
    "      # question = \"\\n\" + counter*\" \" + \"|->\" + var + \" \" + split_type + \" \" + str(val) \n",
    "      subtree = {question: []}\n",
    "\n",
    "\n",
    "      # Find answers (recursion)\n",
    "      yes_answer = train_tree(left,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "\n",
    "      no_answer = train_tree(right,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "\n",
    "      if yes_answer == no_answer:\n",
    "        subtree = yes_answer\n",
    "\n",
    "      else:\n",
    "        subtree[question].append(yes_answer)\n",
    "        subtree[question].append(no_answer)\n",
    "\n",
    "    # If it doesn't match IG condition, make prediction\n",
    "    else:\n",
    "      pred = make_prediction(data[y],target_factor)\n",
    "      return pred\n",
    "\n",
    "   # Drop dataset if doesn't match depth or sample conditions\n",
    "  else:\n",
    "    pred = make_prediction(data[y],target_factor)\n",
    "    return pred\n",
    "\n",
    "  return subtree\n",
    "\n",
    "\n",
    "max_depth = 5\n",
    "min_samples_split = 20\n",
    "min_information_gain  = 1e-5\n",
    "\n",
    "\n",
    "decisiones = train_tree(data,'obese',True, max_depth,min_samples_split,min_information_gain)\n",
    "\n",
    "\n",
    "decisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_datos(observacion, arbol):\n",
    "  question = list(arbol.keys())[0] \n",
    "\n",
    "  if question.split()[1] == '<=':\n",
    "\n",
    "    if observacion[question.split()[0]] <= float(question.split()[2]):\n",
    "      answer = arbol[question][0]\n",
    "    else:\n",
    "      answer = arbol[question][1]\n",
    "\n",
    "  else:\n",
    "\n",
    "    if observacion[question.split()[0]] in (question.split()[2]):\n",
    "      answer = arbol[question][0]\n",
    "    else:\n",
    "      answer = arbol[question][1]\n",
    "\n",
    "  # If the answer is not a dictionary\n",
    "  if not isinstance(answer, dict):\n",
    "    return answer\n",
    "  else:\n",
    "    residual_tree = answer\n",
    "    return clasificar_datos(observacion, answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlgorithm Accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43maccuracy\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print('Algorithm Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gapminder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgapminder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gapminder\n\u001b[0;32m      3\u001b[0m gapminder_lite \u001b[38;5;241m=\u001b[39m gapminder\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlifeExp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgdpPercap\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m gapminder_decission \u001b[38;5;241m=\u001b[39m train_tree(gapminder_lite,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlifeExp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mTrue\u001b[39;00m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gapminder'"
     ]
    }
   ],
   "source": [
    "from gapminder import gapminder\n",
    "\n",
    "gapminder_lite = gapminder.loc[:,['lifeExp','pop','gdpPercap']]\n",
    "\n",
    "gapminder_decission = train_tree(gapminder_lite,'lifeExp',True, max_depth=5)\n",
    "gapminder_decission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
