{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('data iris.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat kamus untuk memetakan kategori ke angka\n",
    "class_mapping = {label: idx for idx, label in enumerate(df['class'].unique())}\n",
    "\n",
    "# Terapkan pemetaan ke kolom 'class'\n",
    "df['class'] = df['class'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1).values\n",
    "y = df['class'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "# # Load data\n",
    "# iris = load_iris()\n",
    "# X, y = iris.data, iris.target.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X):\n",
    "    \"\"\"\n",
    "    Standardizes the data in the array X.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Features array of shape (n_samples, n_features).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The standardized features array.\n",
    "    \"\"\"\n",
    "    # Calculate the mean and standard deviation of each feature\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "\n",
    "    # Standardize the data\n",
    "    X = (X - mean) / std\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \"\"\"\n",
    "    A class representing a node in a decision tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, gain=None, value=None):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the Node class.\n",
    "\n",
    "        Args:\n",
    "            feature: The feature used for splitting at this node. Defaults to None.\n",
    "            threshold: The threshold used for splitting at this node. Defaults to None.\n",
    "            left: The left child node. Defaults to None.\n",
    "            right: The right child node. Defaults to None.\n",
    "            gain: The gain of the split. Defaults to None.\n",
    "            value: If this node is a leaf node, this attribute represents the predicted value\n",
    "                for the target variable. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.gain = gain\n",
    "        self.value = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    \"\"\"\n",
    "    A decision tree classifier for binary classification problems.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_samples=2, max_depth=2):\n",
    "        \"\"\"\n",
    "        Constructor for DecisionTree class.\n",
    "\n",
    "        Parameters:\n",
    "            min_samples (int): Minimum number of samples required to split an internal node.\n",
    "            max_depth (int): Maximum depth of the decision tree.\n",
    "        \"\"\"\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def split_data(self, dataset, feature, threshold):\n",
    "        \"\"\"\n",
    "        Splits the given dataset into two datasets based on the given feature and threshold.\n",
    "\n",
    "        Parameters:\n",
    "            dataset (ndarray): Input dataset.\n",
    "            feature (int): Index of the feature to be split on.\n",
    "            threshold (float): Threshold value to split the feature on.\n",
    "\n",
    "        Returns:\n",
    "            left_dataset (ndarray): Subset of the dataset with values less than or equal to the threshold.\n",
    "            right_dataset (ndarray): Subset of the dataset with values greater than the threshold.\n",
    "        \"\"\"\n",
    "        # Create empty arrays to store the left and right datasets\n",
    "        left_dataset = []\n",
    "        right_dataset = []\n",
    "        \n",
    "        # Loop over each row in the dataset and split based on the given feature and threshold\n",
    "        for row in dataset:\n",
    "            if row[feature] <= threshold:\n",
    "                left_dataset.append(row)\n",
    "            else:\n",
    "                right_dataset.append(row)\n",
    "\n",
    "        # Convert the left and right datasets to numpy arrays and return\n",
    "        left_dataset = np.array(left_dataset)\n",
    "        right_dataset = np.array(right_dataset)\n",
    "        return left_dataset, right_dataset\n",
    "\n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Computes the entropy of the given label values.\n",
    "\n",
    "        Parameters:\n",
    "            y (ndarray): Input label values.\n",
    "\n",
    "        Returns:\n",
    "            entropy (float): Entropy of the given label values.\n",
    "        \"\"\"\n",
    "        entropy = 0\n",
    "\n",
    "        # Find the unique label values in y and loop over each value\n",
    "        labels = np.unique(y)\n",
    "        for label in labels:\n",
    "            # Find the examples in y that have the current label\n",
    "            label_examples = y[y == label]\n",
    "            # Calculate the ratio of the current label in y\n",
    "            pl = len(label_examples) / len(y)\n",
    "            # Calculate the entropy using the current label and ratio\n",
    "            entropy += -pl * np.log2(pl)\n",
    "\n",
    "        # Return the final entropy value\n",
    "        return entropy\n",
    "\n",
    "    def information_gain(self, parent, left, right):\n",
    "        \"\"\"\n",
    "        Computes the information gain from splitting the parent dataset into two datasets.\n",
    "\n",
    "        Parameters:\n",
    "            parent (ndarray): Input parent dataset.\n",
    "            left (ndarray): Subset of the parent dataset after split on a feature.\n",
    "            right (ndarray): Subset of the parent dataset after split on a feature.\n",
    "\n",
    "        Returns:\n",
    "            information_gain (float): Information gain of the split.\n",
    "        \"\"\"\n",
    "        # set initial information gain to 0\n",
    "        information_gain = 0\n",
    "        # compute entropy for parent\n",
    "        parent_entropy = self.entropy(parent)\n",
    "        # calculate weight for left and right nodes\n",
    "        weight_left = len(left) / len(parent)\n",
    "        weight_right= len(right) / len(parent)\n",
    "        # compute entropy for left and right nodes\n",
    "        entropy_left, entropy_right = self.entropy(left), self.entropy(right)\n",
    "        # calculate weighted entropy \n",
    "        weighted_entropy = weight_left * entropy_left + weight_right * entropy_right\n",
    "        # calculate information gain \n",
    "        information_gain = parent_entropy - weighted_entropy\n",
    "        return information_gain\n",
    "\n",
    "    \n",
    "    def best_split(self, dataset, num_samples, num_features):\n",
    "        \"\"\"\n",
    "        Finds the best split for the given dataset.\n",
    "\n",
    "        Args:\n",
    "        dataset (ndarray): The dataset to split.\n",
    "        num_samples (int): The number of samples in the dataset.\n",
    "        num_features (int): The number of features in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary with the best split feature index, threshold, gain, \n",
    "              left and right datasets.\n",
    "        \"\"\"\n",
    "        # dictionary to store the best split values\n",
    "        best_split = {'gain':- 1, 'feature': None, 'threshold': None}\n",
    "        # loop over all the features\n",
    "        for feature_index in range(num_features):\n",
    "            #get the feature at the current feature_index\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            #get unique values of that feature\n",
    "            thresholds = np.unique(feature_values)\n",
    "            # loop over all values of the feature\n",
    "            for threshold in thresholds:\n",
    "                # get left and right datasets\n",
    "                left_dataset, right_dataset = self.split_data(dataset, feature_index, threshold)\n",
    "                # check if either datasets is empty\n",
    "                if len(left_dataset) and len(right_dataset):\n",
    "                    # get y values of the parent and left, right nodes\n",
    "                    y, left_y, right_y = dataset[:, -1], left_dataset[:, -1], right_dataset[:, -1]\n",
    "                    # compute information gain based on the y values\n",
    "                    information_gain = self.information_gain(y, left_y, right_y)\n",
    "                    # update the best split if conditions are met\n",
    "                    if information_gain > best_split[\"gain\"]:\n",
    "                        best_split[\"feature\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"left_dataset\"] = left_dataset\n",
    "                        best_split[\"right_dataset\"] = right_dataset\n",
    "                        best_split[\"gain\"] = information_gain\n",
    "        return best_split\n",
    "\n",
    "    \n",
    "    def calculate_leaf_value(self, y):\n",
    "        \"\"\"\n",
    "        Calculates the most occurring value in the given list of y values.\n",
    "\n",
    "        Args:\n",
    "            y (list): The list of y values.\n",
    "\n",
    "        Returns:\n",
    "            The most occurring value in the list.\n",
    "        \"\"\"\n",
    "        y = list(y)\n",
    "        #get the highest present class in the array\n",
    "        most_occuring_value = max(y, key=y.count)\n",
    "        return most_occuring_value\n",
    "    \n",
    "    def build_tree(self, dataset, current_depth=0):\n",
    "        \"\"\"\n",
    "        Recursively builds a decision tree from the given dataset.\n",
    "\n",
    "        Args:\n",
    "        dataset (ndarray): The dataset to build the tree from.\n",
    "        current_depth (int): The current depth of the tree.\n",
    "\n",
    "        Returns:\n",
    "        Node: The root node of the built decision tree.\n",
    "        \"\"\"\n",
    "        # split the dataset into X, y values\n",
    "        X, y = dataset[:, :-1], dataset[:, -1]\n",
    "        n_samples, n_features = X.shape\n",
    "        # keeps spliting until stopping conditions are met\n",
    "        if n_samples >= self.min_samples and current_depth <= self.max_depth:\n",
    "            # Get the best split\n",
    "            best_split = self.best_split(dataset, n_samples, n_features)\n",
    "            # Check if gain isn't zero\n",
    "            if best_split[\"gain\"]:\n",
    "                # continue splitting the left and the right child. Increment current depth\n",
    "                left_node = self.build_tree(best_split[\"left_dataset\"], current_depth + 1)\n",
    "                right_node = self.build_tree(best_split[\"right_dataset\"], current_depth + 1)\n",
    "                # return decision node\n",
    "                return Node(best_split[\"feature\"], best_split[\"threshold\"],\n",
    "                            left_node, right_node, best_split[\"gain\"])\n",
    "\n",
    "        # compute leaf node value\n",
    "        leaf_value = self.calculate_leaf_value(y)\n",
    "        # return leaf node value\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Builds and fits the decision tree to the given X and y values.\n",
    "\n",
    "        Args:\n",
    "        X (ndarray): The feature matrix.\n",
    "        y (ndarray): The target values.\n",
    "        \"\"\"\n",
    "        dataset = np.concatenate((X, y), axis=1)  \n",
    "        self.root = self.build_tree(dataset)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the class labels for each instance in the feature matrix X.\n",
    "\n",
    "        Args:\n",
    "        X (ndarray): The feature matrix to make predictions for.\n",
    "\n",
    "        Returns:\n",
    "        list: A list of predicted class labels.\n",
    "        \"\"\"\n",
    "        # Create an empty list to store the predictions\n",
    "        predictions = []\n",
    "        # For each instance in X, make a prediction by traversing the tree\n",
    "        for x in X:\n",
    "            prediction = self.make_prediction(x, self.root)\n",
    "            # Append the prediction to the list of predictions\n",
    "            predictions.append(prediction)\n",
    "        # Convert the list to a numpy array and return it\n",
    "        np.array(predictions)\n",
    "        return predictions\n",
    "    \n",
    "    def make_prediction(self, x, node):\n",
    "        \"\"\"\n",
    "        Traverses the decision tree to predict the target value for the given feature vector.\n",
    "\n",
    "        Args:\n",
    "        x (ndarray): The feature vector to predict the target value for.\n",
    "        node (Node): The current node being evaluated.\n",
    "\n",
    "        Returns:\n",
    "        The predicted target value for the given feature vector.\n",
    "        \"\"\"\n",
    "        # if the node has value i.e it's a leaf node extract it's value\n",
    "        if node.value != None: \n",
    "            return node.value\n",
    "        else:\n",
    "            #if it's node a leaf node we'll get it's feature and traverse through the tree accordingly\n",
    "            feature = x[node.feature]\n",
    "            if feature <= node.threshold:\n",
    "                return self.make_prediction(x, node.left)\n",
    "            else:\n",
    "                return self.make_prediction(x, node.right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, random_state=41, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Features array of shape (n_samples, n_features).\n",
    "        y (numpy.ndarray): Target array of shape (n_samples,).\n",
    "        random_state (int): Seed for the random number generator. Default is 42.\n",
    "        test_size (float): Proportion of samples to include in the test set. Default is 0.2.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[numpy.ndarray]: A tuple containing X_train, X_test, y_train, y_test.\n",
    "    \"\"\"\n",
    "    # Get number of samples\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Set the seed for the random number generator\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Shuffle the indices\n",
    "    shuffled_indices = np.random.permutation(np.arange(n_samples))\n",
    "\n",
    "    # Determine the size of the test set\n",
    "    test_size = int(n_samples * test_size)\n",
    "\n",
    "    # Split the indices into test and train\n",
    "    test_indices = shuffled_indices[:test_size]\n",
    "    train_indices = shuffled_indices[test_size:]\n",
    "\n",
    "    # Split the features and target arrays into test and train\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of a classification model.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "        y_true (numpy array): A numpy array of true labels for each data point.\n",
    "        y_pred (numpy array): A numpy array of predicted labels for each data point.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        float: The accuracy of the model\n",
    "    \"\"\"\n",
    "    y_true = y_true.flatten()\n",
    "    total_samples = len(y_true)\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    return (correct_predictions / total_samples) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy(y_true, y_pred):\n",
    "    \"\"\"Calculate the balanced accuracy for a multi-class classification problem.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        y_true (numpy array): A numpy array of true labels for each data point.\n",
    "        y_pred (numpy array): A numpy array of predicted labels for each data point.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        balanced_acc : The balanced accuracyof the model\n",
    "        \n",
    "    \"\"\"\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = y_true.flatten()\n",
    "    # Get the number of classes\n",
    "    n_classes = len(np.unique(y_true))\n",
    "\n",
    "    # Initialize an array to store the sensitivity and specificity for each class\n",
    "    sen = []\n",
    "    spec = []\n",
    "    # Loop over each class\n",
    "    for i in range(n_classes):\n",
    "        # Create a mask for the true and predicted values for class i\n",
    "        mask_true = y_true == i\n",
    "        mask_pred = y_pred == i\n",
    "\n",
    "        # Calculate the true positive, true negative, false positive, and false negative values\n",
    "        TP = np.sum(mask_true & mask_pred)\n",
    "        TN = np.sum((mask_true != True) & (mask_pred != True))\n",
    "        FP = np.sum((mask_true != True) & mask_pred)\n",
    "        FN = np.sum(mask_true & (mask_pred != True))\n",
    "\n",
    "        # Calculate the sensitivity (true positive rate) and specificity (true negative rate)\n",
    "        sensitivity = TP / (TP + FN)\n",
    "        specificity = TN / (TN + FP)\n",
    "\n",
    "        # Store the sensitivity and specificity for class i\n",
    "        sen.append(sensitivity)\n",
    "        spec.append(specificity)\n",
    "    # Calculate the balanced accuracy as the average of the sensitivity and specificity for each class\n",
    "    average_sen =  np.mean(sen)\n",
    "    average_spec =  np.mean(spec)\n",
    "    balanced_acc = (average_sen + average_spec) / n_classes\n",
    "\n",
    "    return balanced_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=41, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Accuracy: 0.9\n",
      "Model's Balanced Accuracy: 0.6196969696969697\n"
     ]
    }
   ],
   "source": [
    "#create model instance\n",
    "model = DecisionTree(2, 2)\n",
    "\n",
    "# Fit the decision tree model to the training data.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data.\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluating metrics\n",
    "print(f\"Model's Accuracy: {accuracy(y_test, predictions)}\")\n",
    "print(f\"Model's Balanced Accuracy: {balanced_accuracy(y_test, predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model's Accuracy: 0.8333333333333334\n",
      "Model's Balanced Accuracy: 0.585778841041999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create a decision tree classifier model object.\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the decision tree classifier model using the training data.\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test data.\n",
    "predictions_sklearn = decision_tree_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluating metrics\n",
    "print(f\" Model's Accuracy: {accuracy(y_test, predictions_sklearn)}\")\n",
    "print(f\"Model's Balanced Accuracy: {balanced_accuracy(y_test, predictions_sklearn)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'True Positive (TP)': 8, 'False Negative (FN)': 0, 'False Positive (FP)': 0, 'True Negative (TN)': 9}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Membuat Confusion Matrix secara manual.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true : list atau array (label sebenarnya)\n",
    "    y_pred : list atau array (label yang diprediksi)\n",
    "    \n",
    "    Returns:\n",
    "    matrix : dict dengan nilai TP, TN, FP, FN\n",
    "    \"\"\"\n",
    "    # Inisialisasi nilai awal\n",
    "    TP = TN = FP = FN = 0\n",
    "    \n",
    "    # Looping untuk menghitung TP, TN, FP, FN\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            TP += 1\n",
    "        elif yt == 0 and yp == 0:\n",
    "            TN += 1\n",
    "        elif yt == 0 and yp == 1:\n",
    "            FP += 1\n",
    "        elif yt == 1 and yp == 0:\n",
    "            FN += 1\n",
    "            \n",
    "    # Membuat dictionary confusion matrix\n",
    "    matrix = {\n",
    "        \"True Positive (TP)\": TP,\n",
    "        \"False Negative (FN)\": FN,\n",
    "        \"False Positive (FP)\": FP,\n",
    "        \"True Negative (TN)\": TN\n",
    "    }\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# Contoh data label asli dan prediksi model\n",
    "# y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
    "# y_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "# Panggil fungsi\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  8  3]\n",
      " [ 0  0 10]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, labels=None):\n",
    "    \"\"\"\n",
    "    Membuat confusion matrix dari label sebenarnya dan prediksi.\n",
    "    :param y_true: List atau array label sebenarnya\n",
    "    :param y_pred: List atau array label prediksi\n",
    "    :param labels: List dari semua label unik (opsional)\n",
    "    :return: Confusion matrix sebagai numpy array\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    \n",
    "    matrix = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        matrix[label_to_index[true], label_to_index[pred]] += 1\n",
    "    \n",
    "    return matrix, labels\n",
    "\n",
    "def plot_confusion_matrix(cm, labels):\n",
    "    \"\"\"\n",
    "    Memvisualisasikan confusion matrix.\n",
    "    :param cm: Confusion matrix dalam bentuk numpy array\n",
    "    :param labels: Label kelas\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# Contoh penggunaan\n",
    "# y_true = [\"cat\", \"dog\", \"dog\", \"cat\", \"cat\", \"dog\", \"cat\", \"bird\", \"bird\", \"bird\"]\n",
    "# y_pred = [\"dog\", \"dog\", \"dog\", \"cat\", \"bird\", \"dog\", \"cat\", \"bird\", \"cat\", \"bird\"]\n",
    "\n",
    "y_test1 = np.ravel(y_test)  # Mengubah ke array 1D jika masih dalam bentuk (n,1)\n",
    "predictions1 = np.ravel(predictions)\n",
    "\n",
    "\n",
    "cm, labels = confusion_matrix(y_test1, predictions1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
